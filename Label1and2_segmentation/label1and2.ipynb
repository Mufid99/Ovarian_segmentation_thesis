{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import nrrd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nnunet\n",
    "\n",
    "# from nnunet.dataset_conversion.utils import dataset_conversion\n",
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import display\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, List, Union\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "from batchgenerators.utilities.file_and_folder_operations import *"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "cuda_dev = '0' #GPU device 0 (can be changed if multiple GPUs are available)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:\" + cuda_dev if use_cuda else \"cpu\")\n",
    "\n",
    "print('Device: ' + str(device))\n",
    "if use_cuda:\n",
    "    print('GPU: ' + str(torch.cuda.get_device_name(int(cuda_dev))))      "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda:0\n",
      "GPU: GeForce GTX TITAN X\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# directories\n",
    "# change these to match where your existing data is and should be\n",
    "# name of dataset directory\n",
    "dataset_name = \"label1and2/\"\n",
    "# name of task for nnU-Net to recognise\n",
    "task_name = \"Task104_Ovary/\"\n",
    "base_dir = '/vol/bitbucket/ma3720/thesis/datasets/' + dataset_name\n",
    "raw_data_dir = '/vol/bitbucket/ma3720/thesis/nnUNet_raw/nnUNet_raw_data/'\n",
    "tr_img_dir = raw_data_dir + task_name + 'imagesTr/'\n",
    "tr_label_dir = raw_data_dir + task_name + 'labelsTr/'\n",
    "ts_img_dir = raw_data_dir + task_name + 'imagesTs/'\n",
    "ts_label_dir = raw_data_dir + task_name + 'labelsTs/'\n",
    "json_dir = raw_data_dir + task_name + 'dataset.json'\n",
    "predicted_dir = '/vol/bitbucket/ma3720/thesis/results/' + task_name\n",
    "overlayed_dir = '/vol/bitbucket/ma3720/thesis/overlayed/' + task_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# creates a folder at given path containing the task for nnunet \n",
    "Path(raw_data_dir + task_name).mkdir(parents=False, exist_ok=True)\n",
    "Path(tr_img_dir).mkdir(parents=False, exist_ok=True)\n",
    "Path(ts_img_dir).mkdir(parents=False, exist_ok=True)\n",
    "Path(tr_label_dir).mkdir(parents=False, exist_ok=True)\n",
    "Path(ts_label_dir).mkdir(parents=False, exist_ok=True)\n",
    "Path(predicted_dir).mkdir(parents=False, exist_ok=True)\n",
    "Path(overlayed_dir).mkdir(parents=False, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# resample image to required size by using interpolation\n",
    "# code obtained from https://stackoverflow.com/questions/48065117/simpleitk-resize-images\n",
    "def resample_image(img, is_label):\n",
    "    dimension = img.GetDimension()\n",
    "    reference_physical_size = np.zeros(dimension)\n",
    "    reference_physical_size[:] = [(sz-1)*spc if sz*spc>mx  else mx for sz,spc,mx in zip(img.GetSize(), img.GetSpacing(), reference_physical_size)]\n",
    "\n",
    "    reference_origin = np.zeros(dimension)\n",
    "    reference_direction = np.identity(dimension).flatten()\n",
    "    reference_size = [256]*dimension # Arbitrary sizes, smallest size that yields desired results. \n",
    "    reference_spacing = [ phys_sz/(sz-1) for sz,phys_sz in zip(reference_size, reference_physical_size) ]\n",
    "\n",
    "    reference_image = sitk.Image(reference_size, img.GetPixelIDValue())\n",
    "    reference_image.SetOrigin(reference_origin)\n",
    "    reference_image.SetSpacing(reference_spacing)\n",
    "    reference_image.SetDirection(reference_direction)\n",
    "    reference_center = np.array(reference_image.TransformContinuousIndexToPhysicalPoint(np.array(reference_image.GetSize())/2.0))\n",
    "\n",
    "    transform = sitk.AffineTransform(dimension)\n",
    "    transform.SetMatrix(img.GetDirection())\n",
    "    transform.SetTranslation(np.array(img.GetOrigin()) - reference_origin)\n",
    "\n",
    "    centering_transform = sitk.TranslationTransform(dimension)\n",
    "    img_center = np.array(img.TransformContinuousIndexToPhysicalPoint(np.array(img.GetSize())/2.0))\n",
    "\n",
    "    centering_transform.SetOffset(np.array(transform.GetInverse().TransformPoint(img_center) - reference_center))\n",
    "    centered_transform = sitk.Transform(transform)\n",
    "    centered_transform.AddTransform(centering_transform)\n",
    "\n",
    "    if is_label:\n",
    "        return sitk.Resample(img, reference_image, centered_transform, sitk.sitkNearestNeighbor, 0.0)\n",
    "    else:\n",
    "        return sitk.Resample(img, reference_image, centered_transform, sitk.sitkLinear, 0.0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def crop_image(img):\n",
    "    to_crop = int(img.GetSize()[1] * 0.1) # removes this many rows from the top\n",
    "    return img[:, to_crop:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# used to create the nifti files for both segmentations and images to be used by nnunet\n",
    "# obtained from nnunet library but some changes were made\n",
    "def convert_2d_image_to_nifti_new(img, input_filename: str, output_filename_truncated: str, spacing=(999, 1, 1),\n",
    "                              transform=None, is_seg: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Reads an image (must be a format that it recognized by skimage.io.imread) and converts it into a series of niftis.\n",
    "    The image can have an arbitrary number of input channels which will be exported separately (_0000.nii.gz,\n",
    "    _0001.nii.gz, etc for images and only .nii.gz for seg).\n",
    "    Spacing can be ignored most of the time.\n",
    "    !!!2D images are often natural images which do not have a voxel spacing that could be used for resampling. These images\n",
    "    must be resampled by you prior to converting them to nifti!!!\n",
    "    Datasets converted with this utility can only be used with the 2d U-Net configuration of nnU-Net\n",
    "    If Transform is not None it will be applied to the image after loading.\n",
    "    Segmentations will be converted to np.uint32!\n",
    "    :param is_seg:\n",
    "    :param transform:\n",
    "    :param input_filename:\n",
    "    :param output_filename_truncated: do not use a file ending for this one! Example: output_name='./converted/image1'. This\n",
    "    function will add the suffix (_0000) and file ending (.nii.gz) for you.\n",
    "    :param spacing:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # img = io.imread(input_filename)\n",
    "\n",
    "    if transform is not None:\n",
    "        img = transform(img)\n",
    "\n",
    "    if input_filename.endswith(\".nrrd\"):\n",
    "        img = np.squeeze(img)\n",
    "    elif img.shape[2] == 4:\n",
    "        img = img[:,:,0:3]\n",
    "\n",
    "    if len(img.shape) == 2:  # 2d image with no color channels\n",
    "        img = img[None, None]  # add dimensions\n",
    "    else:\n",
    "        assert len(img.shape) == 3, \"image should be 3d with color channel last but has shape %s\" % str(img.shape)\n",
    "        # we assume that the color channel is the last dimension. Transpose it to be in first\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        # add third dimension\n",
    "        img = img[:, None]\n",
    "    # image is now (c, x, x, z) where x=1 since it's 2d\n",
    "    if is_seg:\n",
    "        assert img.shape[0] == 1, 'segmentations can only have one color channel, not sure what happened here'\n",
    "    \n",
    "    for j, i in enumerate(img):\n",
    "\n",
    "        if is_seg:\n",
    "            i = i.astype(np.uint32)\n",
    "\n",
    "        itk_img = sitk.GetImageFromArray(i)\n",
    "        itk_img.SetSpacing(list(spacing)[::-1])\n",
    "        if not is_seg:\n",
    "            sitk.WriteImage(itk_img, output_filename_truncated + \"_%04.0d.nii.gz\" % j)\n",
    "        else:\n",
    "            sitk.WriteImage(itk_img, output_filename_truncated + \".nii.gz\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# obtained from nnunet library\n",
    "def get_identifiers_from_splitted_files(folder: str):\n",
    "    uniques = np.unique([i[:-12] for i in subfiles(folder, suffix='.nii.gz', join=False)])\n",
    "    return uniques\n",
    "\n",
    "def generate_dataset_json(output_file: str, imagesTr_dir: str, imagesTs_dir: str, modalities: Tuple,\n",
    "                          labels: dict, dataset_name: str, license: str = \"hands off!\", dataset_description: str = \"\",\n",
    "                          dataset_reference=\"\", dataset_release='0.0'):\n",
    "    \"\"\"\n",
    "    :param output_file: This needs to be the full path to the dataset.json you intend to write, so\n",
    "    output_file='DATASET_PATH/dataset.json' where the folder DATASET_PATH points to is the one with the\n",
    "    imagesTr and labelsTr subfolders\n",
    "    :param imagesTr_dir: path to the imagesTr folder of that dataset\n",
    "    :param imagesTs_dir: path to the imagesTs folder of that dataset. Can be None\n",
    "    :param modalities: tuple of strings with modality names. must be in the same order as the images (first entry\n",
    "    corresponds to _0000.nii.gz, etc). Example: ('T1', 'T2', 'FLAIR').\n",
    "    :param labels: dict with int->str (key->value) mapping the label IDs to label names. Note that 0 is always\n",
    "    supposed to be background! Example: {0: 'background', 1: 'edema', 2: 'enhancing tumor'}\n",
    "    :param dataset_name: The name of the dataset. Can be anything you want\n",
    "    :param license:\n",
    "    :param dataset_description:\n",
    "    :param dataset_reference: website of the dataset, if available\n",
    "    :param dataset_release:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_identifiers = get_identifiers_from_splitted_files(imagesTr_dir)\n",
    "\n",
    "    if imagesTs_dir is not None:\n",
    "        test_identifiers = get_identifiers_from_splitted_files(imagesTs_dir)\n",
    "    else:\n",
    "        test_identifiers = []\n",
    "\n",
    "    json_dict = {}\n",
    "    json_dict['name'] = dataset_name\n",
    "    json_dict['description'] = dataset_description\n",
    "    json_dict['tensorImageSize'] = \"4D\"\n",
    "    json_dict['reference'] = dataset_reference\n",
    "    json_dict['licence'] = license\n",
    "    json_dict['release'] = dataset_release\n",
    "    json_dict['modality'] = {str(i): modalities[i] for i in range(len(modalities))}\n",
    "    json_dict['labels'] = {str(i): labels[i] for i in labels.keys()}\n",
    "\n",
    "    json_dict['numTraining'] = len(train_identifiers)\n",
    "    json_dict['numTest'] = len(test_identifiers)\n",
    "    json_dict['training'] = [\n",
    "        {'image': \"./imagesTr/%s.nii.gz\" % i, \"label\": \"./labelsTr/%s.nii.gz\" % i} for i\n",
    "        in\n",
    "        train_identifiers]\n",
    "    json_dict['test'] = [\"./imagesTs/%s.nii.gz\" % i for i in test_identifiers]\n",
    "\n",
    "    if not output_file.endswith(\"dataset.json\"):\n",
    "        print(\"WARNING: output file name is not dataset.json! This may be intentional or not. You decide. \"\n",
    "              \"Proceeding anyways...\")\n",
    "    save_json(json_dict, os.path.join(output_file))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "files =  os.listdir(base_dir)\n",
    "# renames all files to remove whitespace. Uncomment this the first time you use on dataset to remove whitespace if needed\n",
    "# for file in files:\n",
    "#     os.rename(base_dir + file, base_dir + file.replace(\" \", \"\"))\n",
    "\n",
    "sorted_files = []\n",
    "# number of images\n",
    "tif_count = 0\n",
    "# number of segmentations\n",
    "nrrd_count = 0\n",
    "for file in sorted(files):\n",
    "    if file.endswith(\".nrrd\") or file.endswith(\"tiff\") or file.endswith(\"tif\"):\n",
    "        if file.endswith(\".nrrd\"):\n",
    "            nrrd_count += 1\n",
    "        else:\n",
    "            tif_count += 1\n",
    "        sorted_files.append(file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# check for dataset integrity and remove files manually. Do not move to next step before all assertions pass.\n",
    "valid = True\n",
    "for i in range(0, int(len(sorted_files)), 2):\n",
    "      # Uncomment this line if you would like to see the segmentations and images line by line\n",
    "      # print(sorted_files[i], sorted_files[i+1])\n",
    "\n",
    "      img1 = sitk.ReadImage(base_dir + sorted_files[i])\n",
    "      arr1 = np.squeeze(sitk.GetArrayFromImage(img1))\n",
    "      img2 = sitk.ReadImage(base_dir + sorted_files[i+1])\n",
    "      arr2 = np.squeeze(sitk.GetArrayFromImage(img2))\n",
    "\n",
    "      if sorted_files[i].endswith(\".nrrd\"):\n",
    "            valid = sorted_files[i+1].endswith(\".tif\") or sorted_files[i+1].endswith(\".tiff\")\n",
    "            assert valid, \"Invalid file and segmentation. This could simply an issue with naming as the files are sorted according to names. So check consistency.\\\n",
    "             If names are fine then there might be an issue with the dataset such as a duplicate image file or a file without a segmentation. The two files to check around (error is in surrounding images) are \"\\\n",
    "                  + sorted_files[i] + \" and \" + sorted_files[i+1] + \" at image index \" + str(i)  \n",
    "            assert len(arr1.shape) == 3, \"Segmentation does not have a shape of 3 (usually an error with the software making segmentations or there is a missing label) \" + sorted_files[i] + \" shape: \" + \" \".join(map(str,arr1.shape))\n",
    "            assert arr1.shape[2] == 2, \"Segmentation does not have 2 labels\"\n",
    "            # This is commented out because there was an error when making segmentations\n",
    "            # assert not (arr1==[0,1]).all(2).any(), \"Label 2 is not contained within label 1 in segmentation file: \"  + sorted_files[i]\n",
    "      elif sorted_files[i].endswith(\".tif\") or sorted_files[i].endswith(\".tiff\"):\n",
    "            valid = sorted_files[i+1].endswith(\".nrrd\")\n",
    "            assert valid, \"Invalid file and segmentation. This could simply an issue with naming as the files are sorted according to names. So check consistency.\\\n",
    "             If names are fine then there might be an issue with the dataset such as a duplicate image file or a file without a segmentation. The two files to check around (error is in surrounding images) are \"\\\n",
    "                  + sorted_files[i] + \" and \" + sorted_files[i+1] +  \" at image index \" + str(i)\n",
    "            assert len(arr2.shape) == 3, \"Segmentation does not have a shape of 3 (usually an error with the software making segmentations or there is a missing label) \" + sorted_files[i+1] + \" shape: \" + \" \".join(map(str,arr2.shape))\n",
    "            assert arr2.shape[2] == 2, \"Segmentation does not have 2 labels\"\n",
    "            # assert not (arr2==[0,1]).all(2).any(), \"Label 2 is not contained within label 1 in segmentation file: \"  + sorted_files[i+1]\n",
    "      assert arr1.shape[0] == arr2.shape[0] and arr1.shape[1] == arr2.shape[1], \"The image and segmentation do not have matching sizes. The files are: \" + sorted_files[i] + \" has shape \" + \" \".join(map(str,arr1.shape))\\\n",
    "              + \" and \" + sorted_files[i+1] + \" has shape \" + \" \".join(map(str,arr2.shape))\n",
    "\n",
    "assert nrrd_count == tif_count, \"Inbalance in number of images and segmentations \\n Segmentations: \" + str(nrrd_count) + \" Images: \" + str(tif_count)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# chooses images to use in test set\n",
    "np.random.seed(2)\n",
    "test_files = np.random.choice(range(0, int(len(sorted_files)), 2), int(len(sorted_files) * 0.05), replace=False)\n",
    "# These files (only one of image or segmentation appears below) will be used in the test set\n",
    "print(np.array(sorted_files)[test_files.astype(int)])\n",
    "print(len(test_files))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['18872_0019L12.TIF.tif' '23556_0034L12.TIF.tif' '23530tiff_9L12.tif'\n",
      " '13355_6L12.tif' '18510_0025L12.TIF.tif' '17860_0032L12.TIF.tif'\n",
      " '18853_0033L12.TIF.tif' '23866_0018L12Segmentation.seg.nrrd'\n",
      " '24306_0015L12.TIF.tif' '14654_7L12.tif' '24306_0019L12.TIF.tif'\n",
      " '23522_-3L12.tif' '15346_0001L12.TIF.tif' '19623_0011L12.TIF.tif'\n",
      " '17303_0044L12.TIF.tif' '23941_0014L12Segmentation.seg.nrrd'\n",
      " '14117_1L12.tif' '13142_0009L12.TIF.tif' '15526_0028L12.TIF.tif'\n",
      " '23677_0001L12Segmentation.seg.nrrd' '23506_0048L12.TIF.tif'\n",
      " '18441_0026L12.TIF.tif' '23529tiff_5L12.tif' '19436_0028L12.TIF.tif'\n",
      " '23676tiff_2L12.tif' '17853_0019L12.TIF.tif' '18441_0024L12.TIF.tif'\n",
      " '17584_0009L12Segmentation.seg.nrrd' '23742_0015L12Segmentation.seg.nrrd'\n",
      " '23495tiff_7L12.Segmentation.seg.nrrd' '23649_0013L12.TIF.tif'\n",
      " '23644_6L12.tif' '16683_0018L12.TIF.tif' '23536.-3L12.tif'\n",
      " '23478tiff_1L12.tif' '14984_0035L12Segmentation_1.seg.nrrd'\n",
      " '12041_3L12Segmentation.seg.nrrd' '13291_0010L12.TIF.tif'\n",
      " '18786tiff_7L12.Segmentation_1.seg.nrrd' '14226_4L12..tif'\n",
      " '23945_0017L12.TIF.tif']\n",
      "41\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# fills up the folders with the dataset\n",
    "for i in range(0, int(len(sorted_files)), 2):\n",
    "    # second file is the one to get the name from \n",
    "    if sorted_files[i].endswith(\".nrrd\"):\n",
    "        img = sitk.ReadImage(base_dir + sorted_files[i+1])\n",
    "        lbl = sitk.ReadImage(base_dir + sorted_files[i])\n",
    "        lbl_arr = np.squeeze(sitk.GetArrayFromImage(lbl))\n",
    "        # If image has pixel with label 2 and not label 1 then add label 1\n",
    "        if (lbl_arr==[0,1]).all(2).any():\n",
    "            lbl_arr[(lbl_arr==[0,1]).all(2)] = [1,1]\n",
    "        # Sums all values in 3rd dimension so that we can know to which class a pixel belongs. If both labels exist the label to be predicted will be 2 (both cyst and locule exist at this pixel).\n",
    "        lbl_arr = lbl_arr.sum(axis=-1)\n",
    "        lbl = sitk.GetImageFromArray(lbl_arr)\n",
    "        img_cropped = crop_image(img)\n",
    "        lbl_cropped = crop_image(lbl)\n",
    "        resampled_lbl = resample_image(lbl_cropped, True)\n",
    "        resampled_img = resample_image(img_cropped, False)\n",
    "        resampled_lbl_arr = sitk.GetArrayFromImage(resampled_lbl)\n",
    "        resampled_img_arr = sitk.GetArrayFromImage(resampled_img)\n",
    "        new_file_pre = sorted_files[i+1].split(\".\")[0]\n",
    "        if i in test_files:\n",
    "            convert_2d_image_to_nifti_new(resampled_img_arr, base_dir + sorted_files[i+1], ts_img_dir + new_file_pre)\n",
    "            convert_2d_image_to_nifti_new(resampled_lbl_arr, base_dir + sorted_files[i], ts_label_dir + new_file_pre, is_seg=True) \n",
    "        else:\n",
    "            convert_2d_image_to_nifti_new(resampled_img_arr, base_dir + sorted_files[i+1], tr_img_dir + new_file_pre)\n",
    "            convert_2d_image_to_nifti_new(resampled_lbl_arr, base_dir + sorted_files[i], tr_label_dir + new_file_pre, is_seg=True) \n",
    "    else:\n",
    "        img = sitk.ReadImage(base_dir + sorted_files[i])\n",
    "        lbl = sitk.ReadImage(base_dir + sorted_files[i+1])\n",
    "        lbl_arr = np.squeeze(sitk.GetArrayFromImage(lbl))\n",
    "        # If image has pixel with label 2 and not label 1 then add label 1\n",
    "        if (lbl_arr==[0,1]).all(2).any():\n",
    "            lbl_arr[(lbl_arr==[0,1]).all(2)] = [1,1]\n",
    "        # Sums all values in 3rd dimension so that we can know to which class a pixel belongs. If both labels exist the label to be predicted will be 2 (both cyst and locule exist at this pixel).\n",
    "        lbl_arr = lbl_arr.sum(axis=-1)\n",
    "        lbl = sitk.GetImageFromArray(lbl_arr)\n",
    "        img_cropped = crop_image(img)\n",
    "        lbl_cropped = crop_image(lbl)\n",
    "        resampled_lbl = resample_image(lbl_cropped, True)\n",
    "        resampled_img = resample_image(img_cropped, False)\n",
    "        resampled_lbl_arr = sitk.GetArrayFromImage(resampled_lbl)\n",
    "        resampled_img_arr = sitk.GetArrayFromImage(resampled_img)\n",
    "        new_file_pre = sorted_files[i].split(\".\")[0]\n",
    "        if i in test_files:\n",
    "            convert_2d_image_to_nifti_new(resampled_img_arr, base_dir + sorted_files[i], ts_img_dir + new_file_pre)\n",
    "            convert_2d_image_to_nifti_new(resampled_lbl_arr, base_dir + sorted_files[i+1], ts_label_dir + new_file_pre, is_seg=True) \n",
    "        else:\n",
    "            convert_2d_image_to_nifti_new(resampled_img_arr, base_dir + sorted_files[i], tr_img_dir + new_file_pre)\n",
    "            convert_2d_image_to_nifti_new(resampled_lbl_arr, base_dir + sorted_files[i+1], tr_label_dir + new_file_pre, is_seg=True) \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# create dataset.json file \n",
    "task = 'Task104_Ovary'\n",
    "generate_dataset_json(json_dir, tr_img_dir, ts_img_dir, ('Red', 'Green', 'Blue'), labels={0: 'background', 1: 'cyst', 2: 'locules'}, dataset_name=task)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# overlays segmentations from labels and the predictions from the model. This only works if labels are overlapping and one label is contained within another\n",
    "label_name = 'label_1'\n",
    "label_number = 1\n",
    "Path(overlayed_dir+label_name).mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "# Where to get image, gold standard and predictions from\n",
    "labels_dir = ts_label_dir\n",
    "images_dir = ts_img_dir\n",
    "predicted_dir = predicted_dir\n",
    "\n",
    "results_files = os.listdir(predicted_dir)\n",
    "for file in sorted(results_files):\n",
    "    if file.endswith('gz'):\n",
    "        current_img_name = file.split('.')[0]\n",
    "        extension = '.nii.gz'\n",
    "        # Get RGB slices of image\n",
    "        img0 = sitk.ReadImage(images_dir + current_img_name + '_0000' + extension) \n",
    "        img1 = sitk.ReadImage(images_dir + current_img_name + '_0001' + extension) \n",
    "        img2 = sitk.ReadImage(images_dir + current_img_name + '_0002' + extension)\n",
    "        # Get arrays from images\n",
    "        img0_arr = np.squeeze(sitk.GetArrayFromImage(img0))\n",
    "        img1_arr = np.squeeze(sitk.GetArrayFromImage(img1))\n",
    "        img2_arr = np.squeeze(sitk.GetArrayFromImage(img2))\n",
    "        # Stack the slices to reform rgb image\n",
    "        img_arr = np.stack([img0_arr, img1_arr, img2_arr], axis=2)\n",
    "        img_arr = np.squeeze(img_arr)   \n",
    "        # Get the gold standard and predicted segmentations\n",
    "        prd_img = predicted_dir + current_img_name + extension\n",
    "        lbl_img = labels_dir + current_img_name + extension\n",
    "        prd_img = sitk.ReadImage(prd_img)\n",
    "        prd_img = sitk.GetArrayFromImage(prd_img)\n",
    "        lbl_img = sitk.ReadImage(lbl_img)\n",
    "        lbl_img = sitk.GetArrayFromImage(lbl_img)\n",
    "        lbl_img = np.squeeze(lbl_img)\n",
    "        prd_img = np.squeeze(prd_img)\n",
    "\n",
    "        # Image at this point still has label 1 as only what isn't label 2, since that's how nnU-Net is trained (overlapping is not allowed). To get the actual label 1, we get the union of label 1 and label 2.\n",
    "        fixed_lbl = lbl_img\n",
    "        fixed_lbl[fixed_lbl>label_number] = label_number\n",
    "        fixed_prd = prd_img\n",
    "        fixed_prd[fixed_prd>label_number] = label_number\n",
    "\n",
    "        # gets the gold standard pixels\n",
    "        mask1 = np.ma.masked_where(fixed_lbl != label_number, fixed_lbl)\n",
    "        # gets the predicted pixels\n",
    "        mask2 = np.ma.masked_where(fixed_prd != label_number, fixed_prd)\n",
    "        # removes the overlap\n",
    "        mask3 = np.ma.masked_where(fixed_prd == label_number, mask1)\n",
    "        # removes the overlap\n",
    "        mask4 = np.ma.masked_where(fixed_lbl == label_number, mask2)\n",
    "        # gets the overlap pixels      \n",
    "        mask5 = np.ma.masked_where(fixed_prd != label_number, mask1)\n",
    "\n",
    "        plt.imshow(img_arr)\n",
    "        plt.imshow(mask3, 'viridis_r', alpha=0.5)\n",
    "        plt.imshow(mask4, 'autumn', alpha=0.5)\n",
    "        plt.imshow(mask5, 'brg_r', alpha=0.5)\n",
    "        \n",
    "        plt.savefig(overlayed_dir + label_name + '/' + current_img_name + '.png', dpi=300)\n",
    "        plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89bed8980cd0cfbd108d790ec49c03eab1e3aab671b89b60bacaed1188b73828"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "89bed8980cd0cfbd108d790ec49c03eab1e3aab671b89b60bacaed1188b73828"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}